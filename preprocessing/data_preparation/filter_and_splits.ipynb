{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create splits\n",
    "- Split by city (assuming knowing the city)\n",
    "- Keep only users having at least k reviews (k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os   \n",
    "from itertools import groupby\n",
    "import random\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CITIES = ['charlotte', 'edinburgh', 'lasvegas', 'london', 'phoenix', 'pittsburgh', 'singapore']\n",
    "ifile = '../../../data/input/reviews_all.csv'\n",
    "filtered_reviews_dir = '../../../data/preprocessed/by_city-users_min_3_reviews/reviews/'\n",
    "reviews = pd.read_csv(ifile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data: keep users having at least 3 keywords\n",
    "<pre> \n",
    "Min number of reviews = 3 \n",
    "City\t    #org_users\t#filtered_users\t#org_reviews\t#filtered_reviews\n",
    "charlotte\t69216\t    13985\t        178488\t        112772\n",
    "edinburgh\t8502\t    1484\t        21205\t        12753\n",
    "lasvegas\t362848\t    66630\t        783422\t        428782\n",
    "london\t    31716\t    5495\t        73495\t        42061\n",
    "phoenix\t    193144\t    37923\t        455941\t        269871\n",
    "pittsburgh\t55554\t    11395\t        145384\t        92449\n",
    "singapore\t5316\t    1308\t        17749\t        12878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City\t#org_users\t#filtered_users\t#org_reviews\t#filtered_reviews\n",
      "Saved to  ../../../data/input/by_city/reviews_charlotte.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_edinburgh.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_lasvegas.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_london.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_phoenix.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_pittsburgh.csv\n",
      "Saved to  ../../../data/input/by_city/reviews_singapore.csv\n"
     ]
    }
   ],
   "source": [
    "min_num_reviews = 3\n",
    "print(\"\\t\".join(['City', '#org_users', '#filtered_users', '#org_reviews', '#filtered_reviews']))\n",
    "for city in CITIES: \n",
    "    ofile = os.path.join(filtered_reviews_dir, \"{}.csv\".format(city))\n",
    "    dt = reviews[reviews['city'].isin([city])]\n",
    "    uids = dt['user_id']\n",
    "    uid2freq = {k: len(list(group)) for k, group in groupby(sorted(uids))}\n",
    "    uid2freq_filtered = {k: v for k, v in uid2freq.items() if v >= min_num_reviews}\n",
    "    dt_filtered = dt[dt['user_id'].isin(list(uid2freq_filtered.keys()))]\n",
    "    dt_filtered.to_csv(ofile)\n",
    "    # print(\"Saved to \", ofile)\n",
    "    print(\"\\t\".join([city, str(len(uid2freq)), str(len(uid2freq_filtered)), str(len(dt)), str(len(dt_filtered))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = '../../../data/preprocessed/splits.json'\n",
    "train_p = .8  # train proportion (#users)\n",
    "dev_p = .05  # 5% for dev "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "[city, #train users, #dev users, #test users, %train users, %dev users, %test users]\n",
    "['charlotte', 11188, 699, 2098, 0.8, 0.04998212370396854, 0.15001787629603147]\n",
    "['edinburgh', 1187, 74, 223, 0.7998652291105122, 0.04986522911051213, 0.15026954177897575]\n",
    "['lasvegas', 53304, 3331, 9995, 0.8, 0.049992495872730004, 0.15000750412726999]\n",
    "['london', 4396, 274, 825, 0.8, 0.04986351228389445, 0.15013648771610555]\n",
    "['phoenix', 30338, 1896, 5689, 0.7999894523112623, 0.04999604461672336, 0.15001450307201433]\n",
    "['pittsburgh', 9116, 569, 1710, 0.8, 0.0499341816586222, 0.1500658183413778]\n",
    "['singapore', 1046, 65, 197, 0.7996941896024465, 0.04969418960244648, 0.15061162079510704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charlotte', 11188, 699, 2098, 0.8, 0.04998212370396854, 0.15001787629603147]\n",
      "['edinburgh', 1187, 74, 223, 0.7998652291105122, 0.04986522911051213, 0.15026954177897575]\n",
      "['lasvegas', 53304, 3331, 9995, 0.8, 0.049992495872730004, 0.15000750412726999]\n",
      "['london', 4396, 274, 825, 0.8, 0.04986351228389445, 0.15013648771610555]\n",
      "['phoenix', 30338, 1896, 5689, 0.7999894523112623, 0.04999604461672336, 0.15001450307201433]\n",
      "['pittsburgh', 9116, 569, 1710, 0.8, 0.0499341816586222, 0.1500658183413778]\n",
      "['singapore', 1046, 65, 197, 0.7996941896024465, 0.04969418960244648, 0.15061162079510704]\n"
     ]
    }
   ],
   "source": [
    "split = {}  # {city: {train: [], dev: [], test: []}}\n",
    "for city in CITIES: \n",
    "    dt = pd.read_csv(os.path.join(filtered_reviews_dir, \"reviews_{}.csv\".format(city)))\n",
    "    users = list(set(list(dt['user_id'])))  # unique set of users \n",
    "    random.shuffle(users)  # randomly shuffle users \n",
    "    num_train = int(len(users) * train_p)\n",
    "    num_dev = int(len(users) * dev_p)\n",
    "    train_users = users[:num_train]\n",
    "    dev_users = users[num_train:num_train + num_dev]\n",
    "    test_users = users[num_train+num_dev:]\n",
    "    tmp = {'train': train_users, 'dev': dev_users, 'test': test_users}\n",
    "    split[city] = tmp\n",
    "    print([city, len(train_users), len(dev_users), len(test_users), len(train_users)/len(users), len(dev_users)/len(users), len(test_users)/len(users)])\n",
    "json.dump(split, open(split_file, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check statistic \n",
    "ifile = '../../../data/preprocessed/splits.json'\n",
    "rdir = '../../../data/preprocessed/by_city-users_min_3_reviews/reviews/'\n",
    "split = json.load(open(ifile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City,set,#reviews,#users,#restaurants\n",
      "charlotte\n",
      "edinburgh\n",
      "lasvegas\n",
      "london\n",
      "phoenix\n",
      "pittsburgh\n",
      "singapore\n",
      "charlotte,train,90426,11188,886\n",
      "charlotte,dev,5611,699,854\n",
      "charlotte,test,16735,2098,885\n",
      "edinburgh,train,10342,1187,938\n",
      "edinburgh,dev,441,74,272\n",
      "edinburgh,test,1970,223,678\n",
      "lasvegas,train,343524,53304,868\n",
      "lasvegas,dev,20572,3331,868\n",
      "lasvegas,test,64686,9995,868\n",
      "london,train,33990,4396,986\n",
      "london,dev,1849,274,749\n",
      "london,test,6222,825,974\n",
      "phoenix,train,216488,30338,947\n",
      "phoenix,dev,13571,1896,947\n",
      "phoenix,test,39812,5689,947\n",
      "pittsburgh,train,73558,9116,905\n",
      "pittsburgh,dev,4784,569,857\n",
      "pittsburgh,test,14107,1710,904\n",
      "singapore,train,10615,1046,983\n",
      "singapore,dev,707,65,478\n",
      "singapore,test,1556,197,742\n"
     ]
    }
   ],
   "source": [
    "print(','.join(['City', 'set', '#reviews', '#users', \"#restaurants\"]))\n",
    "lines = []\n",
    "for city, s in split.items():\n",
    "    dt = pd.read_csv(os.path.join(rdir, '{}.csv'.format(city)))\n",
    "    for setname, uids in s.items():\n",
    "        dtmp = dt[dt['user_id'].isin(uids)]\n",
    "        rests = dtmp['rest_id']\n",
    "        lines.append(','.join([city, setname, str(len(dtmp)), str(len(uids)), str(len(set(rests)))]))\n",
    "print(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City,set,#restaurants,#rest_in_train,%rest_in_train\n",
      "charlotte,dev,854,854,1.0\n",
      "charlotte,test,885,885,1.0\n",
      "edinburgh,dev,272,272,1.0\n",
      "edinburgh,test,678,669,0.9867256637168141\n",
      "lasvegas,dev,868,868,1.0\n",
      "lasvegas,test,868,868,1.0\n",
      "london,dev,749,749,1.0\n",
      "london,test,974,974,1.0\n",
      "phoenix,dev,947,947,1.0\n",
      "phoenix,test,947,947,1.0\n",
      "pittsburgh,dev,857,857,1.0\n",
      "pittsburgh,test,904,904,1.0\n",
      "singapore,dev,478,478,1.0\n",
      "singapore,test,742,742,1.0\n"
     ]
    }
   ],
   "source": [
    "# check % restaurants in test and dev that appear in train \n",
    "print(','.join(['City', 'set', '#restaurants', '#rest_in_train', '%rest_in_train']))\n",
    "lines = []\n",
    "for city, s in split.items():\n",
    "    dt = pd.read_csv(os.path.join(rdir, '{}.csv'.format(city)))\n",
    "    dt_train = dt[dt['user_id'].isin(s['train'])]\n",
    "    dt_dev = dt[dt['user_id'].isin(s['dev'])]\n",
    "    dt_test = dt[dt['user_id'].isin(s['test'])]\n",
    "    train_rests = set(dt_train['rest_id'])\n",
    "    dev_rests = list(set(dt_dev['rest_id']))\n",
    "    test_rests = list(set(dt_test['rest_id']))\n",
    "    dev_n = len(train_rests.intersection(dev_rests))\n",
    "    test_n = len(train_rests.intersection(test_rests))\n",
    "    lines.append(','.join([city, 'dev', str(len(dev_rests)), str(dev_n), str(dev_n/len(dev_rests))]))\n",
    "    lines.append(','.join([city, 'test', str(len(test_rests)), str(test_n), str(test_n/len(test_rests))]))\n",
    "print(\"\\n\".join(lines))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
