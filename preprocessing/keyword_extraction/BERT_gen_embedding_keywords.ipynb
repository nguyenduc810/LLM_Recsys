{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db5587cfb844b889732920c62307b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42e9012da71945519ffbf0f246cf7fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c9d0eeb1484e8bba89529375e01708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9fdd5c120024a8b91949970d1e76db5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love natural language processing. It's a fascinating field.\"\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
    "\n",
    "# Add special tokens [CLS] and [SEP]\n",
    "# tokens = ['[CLS]'] + tokens + ['[SEP]']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"/home/ubuntu/duc.nm195858/keyext_LLM/reviews/singapore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['text'][0]\n",
    "texts = data['text'][0].strip().split('.')\n",
    "# for text in texts:\n",
    "\n",
    "# tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,text in enumerate(texts):\n",
    "  if i == 0:\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "  else:\n",
    "    marked_text += text +\" [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] always been a big supporter of wolf [SEP] \\xa0 would drive distant to get my buger fix [SEP] \\xa0 today was just a big disappointment [SEP] \\xa0got a soggy burger unlike wolf's standard [SEP] \\xa0 whoever cooked the burger needs to be retrained [SEP] \\xa0 not letting the meat rest could be the ussue here [SEP] \\xa09/4Well i previously gave a 1 star due to an absolutely soggy french dip burger but got a message/email from the owner himself inviting to make good and make good they did!!! Kudos to a biz/owner that can be bothered with customer feedback [SEP] \\xa0Really do appreciate the boss taking the initiative to engage the customer and for that not only he won back a loyal customer and i am sure i shall be spreading the Wolf Gospel so to speak - thank you [SEP]Sep 29th '18Checked in again for the usual Double and Shroom with Sweet potatoe fries [SEP] \\xa0 Glad to report all good [SEP] [SEP]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "always        2,467\n",
      "been          2,042\n",
      "a             1,037\n",
      "big           2,502\n",
      "supporter    10,129\n",
      "of            1,997\n",
      "wolf          4,702\n",
      "[SEP]           102\n",
      "would         2,052\n",
      "drive         3,298\n",
      "distant       6,802\n",
      "to            2,000\n",
      "get           2,131\n",
      "my            2,026\n",
      "bug          11,829\n",
      "##er          2,121\n",
      "fix           8,081\n",
      "[SEP]           102\n",
      "today         2,651\n",
      "was           2,001\n",
      "just          2,074\n",
      "a             1,037\n",
      "big           2,502\n",
      "disappointment 10,520\n",
      "[SEP]           102\n",
      "got           2,288\n",
      "a             1,037\n",
      "so            2,061\n",
      "##ggy        22,772\n",
      "burger       15,890\n",
      "unlike        4,406\n",
      "wolf          4,702\n",
      "'             1,005\n",
      "s             1,055\n",
      "standard      3,115\n",
      "[SEP]           102\n",
      "whoever       9,444\n",
      "cooked       12,984\n",
      "the           1,996\n",
      "burger       15,890\n",
      "needs         3,791\n",
      "to            2,000\n",
      "be            2,022\n",
      "re            2,128\n",
      "##train      23,654\n",
      "##ed          2,098\n",
      "[SEP]           102\n",
      "not           2,025\n",
      "letting       5,599\n",
      "the           1,996\n",
      "meat          6,240\n",
      "rest          2,717\n",
      "could         2,071\n",
      "be            2,022\n",
      "the           1,996\n",
      "uss           7,234\n",
      "##ue          5,657\n",
      "here          2,182\n",
      "[SEP]           102\n",
      "9             1,023\n",
      "/             1,013\n",
      "4             1,018\n",
      "##well        4,381\n",
      "i             1,045\n",
      "previously    3,130\n",
      "gave          2,435\n",
      "a             1,037\n",
      "1             1,015\n",
      "star          2,732\n",
      "due           2,349\n",
      "to            2,000\n",
      "an            2,019\n",
      "absolutely    7,078\n",
      "so            2,061\n",
      "##ggy        22,772\n",
      "french        2,413\n",
      "dip          16,510\n",
      "burger       15,890\n",
      "but           2,021\n",
      "got           2,288\n",
      "a             1,037\n",
      "message       4,471\n",
      "/             1,013\n",
      "email        10,373\n",
      "from          2,013\n",
      "the           1,996\n",
      "owner         3,954\n",
      "himself       2,370\n",
      "inviting     15,085\n",
      "to            2,000\n",
      "make          2,191\n",
      "good          2,204\n",
      "and           1,998\n",
      "make          2,191\n",
      "good          2,204\n",
      "they          2,027\n",
      "did           2,106\n",
      "!               999\n",
      "!               999\n",
      "!               999\n",
      "ku           13,970\n",
      "##dos        12,269\n",
      "to            2,000\n",
      "a             1,037\n",
      "bi           12,170\n",
      "##z           2,480\n",
      "/             1,013\n",
      "owner         3,954\n",
      "that          2,008\n",
      "can           2,064\n",
      "be            2,022\n",
      "bothered     11,250\n",
      "with          2,007\n",
      "customer      8,013\n",
      "feedback     12,247\n",
      "[SEP]           102\n",
      "really        2,428\n",
      "do            2,079\n",
      "appreciate    9,120\n",
      "the           1,996\n",
      "boss          5,795\n",
      "taking        2,635\n",
      "the           1,996\n",
      "initiative    6,349\n",
      "to            2,000\n",
      "engage        8,526\n",
      "the           1,996\n",
      "customer      8,013\n",
      "and           1,998\n",
      "for           2,005\n",
      "that          2,008\n",
      "not           2,025\n",
      "only          2,069\n",
      "he            2,002\n",
      "won           2,180\n",
      "back          2,067\n",
      "a             1,037\n",
      "loyal         8,884\n",
      "customer      8,013\n",
      "and           1,998\n",
      "i             1,045\n",
      "am            2,572\n",
      "sure          2,469\n",
      "i             1,045\n",
      "shall         4,618\n",
      "be            2,022\n",
      "spreading     9,359\n",
      "the           1,996\n",
      "wolf          4,702\n",
      "gospel        8,036\n",
      "so            2,061\n",
      "to            2,000\n",
      "speak         3,713\n",
      "-             1,011\n",
      "thank         4,067\n",
      "you           2,017\n",
      "[SEP]           102\n",
      "sep          19,802\n",
      "29th         16,318\n",
      "'             1,005\n",
      "18            2,324\n",
      "##che         5,403\n",
      "##cked       18,141\n",
      "in            1,999\n",
      "again         2,153\n",
      "for           2,005\n",
      "the           1,996\n",
      "usual         5,156\n",
      "double        3,313\n",
      "and           1,998\n",
      "sh           14,021\n",
      "##room        9,954\n",
      "with          2,007\n",
      "sweet         4,086\n",
      "potato       14,557\n",
      "##e           2,063\n",
      "fries        22,201\n",
      "[SEP]           102\n",
      "glad          5,580\n",
      "to            2,000\n",
      "report        3,189\n",
      "all           2,035\n",
      "good          2,204\n",
      "[SEP]           102\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Split the sentence into tokens.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenized_text.index('##er')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the text through BERT, and collect all of the hidden states produced\n",
    "# from all 12 layers. \n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor) #, segments_tensors)\n",
    "\n",
    "    # Evaluating the model will return a different number of objects based on \n",
    "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "    # becase we set `output_hidden_states = True`, the third item will be the \n",
    "    # hidden states from all layers. See the documentation for more details:\n",
    "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 186\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the 5th token in our sentence, select its feature values from layer 5.\n",
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
