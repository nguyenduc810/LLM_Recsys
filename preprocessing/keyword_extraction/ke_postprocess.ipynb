{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from pprint import pprint \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords(ifile, ofile, min_freq=3):\n",
    "    data = json.load(open(ifile))\n",
    "    np2count = data['np2count']\n",
    "    valid_kws = [a for a, b in np2count.items() if b >= min_freq]\n",
    "    new_dict = {}\n",
    "    for k, v in data.items():\n",
    "        tmp = {} \n",
    "        for k2 in valid_kws:\n",
    "            tmp[k2] = v[k2]\n",
    "        new_dict[k] = tmp\n",
    "    json.dump(new_dict, open(ofile, 'w'))\n",
    "    print(\"Saved to\", ofile)\n",
    "    \n",
    "\n",
    "def group_keywords_for_users(ifile, ofile):\n",
    "    dt = json.load(open(ifile))\n",
    "    np2users = dt['np2users']\n",
    "    u2kw = {}  # {user: {keyword: freq}}\n",
    "    for kw, u2c in np2users.items():\n",
    "        for u, c in u2c.items():\n",
    "            if u not in u2kw:\n",
    "                u2kw[u] = {} \n",
    "            u2kw[u][kw] = c \n",
    "    json.dump(u2kw, open(ofile, 'w'))\n",
    "    print(\"Saved to\", ofile)\n",
    "\n",
    "\n",
    "def mkdir(idir):\n",
    "    if not os.path.isdir(idir):\n",
    "        os.makedirs(idir)\n",
    "\n",
    "\n",
    "def compute_tfirf(ifile, ofile, irf, default_irf=0.01, sorting=True):\n",
    "    dt = json.load(open(ifile))\n",
    "    u2kw2score = {} \n",
    "    for u, kw2f in dt.items():\n",
    "        kw2score = {}\n",
    "        for kw, f in kw2f.items():\n",
    "            kw2score[kw] = f * irf.get(kw, default_irf)\n",
    "        u2kw2score[u] = kw2score\n",
    "    # sort \n",
    "    if sorting:\n",
    "        tmp = {} \n",
    "        for k, v in u2kw2score.items():\n",
    "            vs = sorted(v.items(), key=lambda x: x[1], reverse=True)\n",
    "            tmp[k] = vs \n",
    "        u2kw2score = tmp\n",
    "    json.dump(u2kw2score, open(ofile, 'w'))\n",
    "    print(\"Saved to\", ofile)\n",
    "    \n",
    "\n",
    "def get_irf(city, irf_dict, irf_dir):\n",
    "    if city not in irf_dict:\n",
    "        irf = json.load(open(os.path.join(irf_dir, city)))\n",
    "        irf_dict[city] = irf\n",
    "    return irf_dict[city]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out keywords based on frequency (min=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for edinburgh\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/keywords_spacy-min_3/test/edinburgh.json\n"
     ]
    }
   ],
   "source": [
    "CITIES = ['edinburgh'] #['charlotte', 'edinburgh', 'lasvegas', 'london', 'phoenix', 'pittsburgh', 'singapore']\n",
    "min_freq = 3\n",
    "for city in CITIES: \n",
    "    print(\"Processing for\", city)\n",
    "    ifile = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/keywords_spacy/test/{}-keywords.json'.format(city)\n",
    "    ofile = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/keywords_spacy-min_{}/test/{}.json'.format(min_freq, city)\n",
    "    filter_keywords(ifile, ofile, min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group keywords for users (for dev/test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for edinburgh-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/test/edinburgh-keywords.json\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "names = ['test'] #['dev', 'test']\n",
    "for setname in names: \n",
    "    idir = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/keywords_spacy/' + setname\n",
    "    odir = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/' + setname\n",
    "    mkdir(odir)\n",
    "    for fname in os.listdir(idir):\n",
    "        if fname.startswith('.') or not fname.endswith(\".json\"):\n",
    "            continue \n",
    "        print(\"Processing for\", fname)\n",
    "        ifile = os.path.join(idir, fname)\n",
    "        ofile = os.path.join(odir, fname)\n",
    "        group_keywords_for_users(ifile, ofile)\n",
    "    print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IRF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/test/edinburgh-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/test/edinburgh-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/phoenix-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/phoenix-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/edinburgh-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/edinburgh-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/london-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/london-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/charlotte-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/charlotte-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/lasvegas-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/lasvegas-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/singapore-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/singapore-keywords.json\n",
      "Processing for /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq/train/pittsburgh-keywords.json\n",
      "Saved to /home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf/train/pittsburgh-keywords.json\n"
     ]
    }
   ],
   "source": [
    "irf_dir = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/keywords_IRF'\n",
    "idir_root = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/raw_freq'\n",
    "odir_root = '/home/ubuntu/duc.nm195858/keyext_LLM/preprocessed/by_city-users_min_3_reviews/user_to_keywords/tf_irf'\n",
    "\n",
    "city2irf = {}\n",
    "\n",
    "for setname in os.listdir(idir_root):\n",
    "    if setname.startswith(\".\"):\n",
    "        continue \n",
    "    idir = os.path.join(idir_root, setname)\n",
    "    odir = os.path.join(odir_root, setname)\n",
    "    mkdir(odir)\n",
    "    for fname in os.listdir(idir):\n",
    "        if fname.startswith(\".\"):\n",
    "            continue\n",
    "        ifile = os.path.join(idir, fname)\n",
    "        ofile = os.path.join(odir, fname)\n",
    "        print(\"Processing for\", ifile)\n",
    "        compute_tfirf(ifile, ofile, irf=get_irf(fname, city2irf, irf_dir))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
